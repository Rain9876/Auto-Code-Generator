{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/python-000000000000.csv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-1c4efd9c6e1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/python-000000000000.csv.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/python-000000000000.csv.gz'"
     ]
    }
   ],
   "source": [
    "file = gzip.open('data/python-000000000000.csv.gz') \n",
    "pf = pd.read_csv(file, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"repo_name\":\"ghandiosm/Test\",\"ref\":\"refs/heads/master\",\"path\":\"addons/mail/models/mail_followers.py\",\"copies\":\"26\",\"content\":\"# -*- coding: utf-8 -*-\\n\\nfrom openerp import api, fields, models\\n\\n\\nclass Followers(models.Model):\\n    \\\"\\\"\\\" mail_followers holds the data related to the follow mechanism inside\\n    Odoo. Partners can choose to follow documents (records) of any kind\\n    that inherits from mail.thread. Following documents allow to receive\\n    notifications for new messages. A subscription is characterized by:\\n\\n    :param: res_model: model of the followed objects\\n    :param: res_id: ID of resource (may be 0 for every objects)\\n    \\\"\\\"\\\"\\n    _name = 'mail.followers'\\n    _rec_name = 'partner_id'\\n    _log_access = False\\n    _description = 'Document Followers'\\n\\n    res_model = fields.Char(\\n        'Related Document Model', required=True, select=1, help='Model of the followed resource')\\n    res_id = fields.Integer(\\n        'Related Document ID', select=1, help='Id of the followed resource')\\n    partner_id = fields.Many2one(\\n        'res.partner', string='Related Partner', ondelete='cascade', select=1)\\n    channel_id = fields.Many2one(\\n        'mail.channel', string='Listener', ondelete='cascade', select=1)\\n    subtype_ids = fields.Many2many(\\n        'mail.message.subtype', string='Subtype',\\n        help=\\\"Message subtypes followed, meaning subtypes that will be pushed onto the user's Wall.\\\")\\n\\n    @api.model\\n    def _add_follower_command(self, res_model, res_ids, partner_data, channel_data, force=True):\\n        \\\"\\\"\\\" Please upate me\\n        :param force: if True, delete existing followers before creating new one\\n                      using the subtypes given in the parameters\\n        \\\"\\\"\\\"\\n        force_mode = force or (all(data for data in partner_data.values()) and all(data for data in channel_data.values()))\\n        generic = []\\n        specific = {}\\n        existing = {}  # {res_id: follower_ids}\\n        p_exist = {}  # {partner_id: res_ids}\\n        c_exist = {}  # {channel_id: res_ids}\\n\\n        followers = self.sudo().search([\\n            '\\u0026',\\n            '\\u0026', ('res_model', '=', res_model), ('res_id', 'in', res_ids),\\n            '|', ('partner_id', 'in', partner_data.keys()), ('channel_id', 'in', channel_data.keys())])\\n\\n        if force_mode:\\n            followers.unlink()\\n        else:\\n            for follower in followers:\\n                existing.setdefault(follower.res_id, list()).append(follower)\\n                if follower.partner_id:\\n                    p_exist.setdefault(follower.partner_id.id, list()).append(follower.res_id)\\n                if follower.channel_id:\\n                    c_exist.setdefault(follower.channel_id.id, list()).append(follower.res_id)\\n\\n        default_subtypes = self.env['mail.message.subtype'].search([\\n            ('default', '=', True),\\n            '|', ('res_model', '=', res_model), ('res_model', '=', False)])\\n\\n        if force_mode:\\n            for pid, data in partner_data.iteritems():\\n                if not data:\\n                    partner_data[pid] = default_subtypes.ids\\n            for cid, data in channel_data.iteritems():\\n                if not data:\\n                    channel_data[cid] = default_subtypes.ids\\n\\n        # create new followers, batch ok\\n        gen_new_pids = [pid for pid in partner_data.keys() if pid not in p_exist]\\n        gen_new_cids = [cid for cid in channel_data.keys() if cid not in c_exist]\\n        for pid in gen_new_pids:\\n            generic.append([0, 0, {'res_model': res_model, 'partner_id': pid, 'subtype_ids': [(6, 0, partner_data.get(pid) or default_subtypes.ids)]}])\\n        for cid in gen_new_cids:\\n            generic.append([0, 0, {'res_model': res_model, 'channel_id': cid, 'subtype_ids': [(6, 0, channel_data.get(cid) or default_subtypes.ids)]}])\\n\\n        # create new followers, each document at a time because of existing followers to avoid erasing\\n        if not force_mode:\\n            for res_id in res_ids:\\n                command = []\\n                doc_followers = existing.get(res_id, list())\\n\\n                new_pids = set(partner_data.keys()) - set([sub.partner_id.id for sub in doc_followers if sub.partner_id]) - set(gen_new_pids)\\n                new_cids = set(channel_data.keys()) - set([sub.channel_id.id for sub in doc_followers if sub.channel_id]) - set(gen_new_cids)\\n\\n                # subscribe new followers\\n                for new_pid in new_pids:\\n                    command.append((0, 0, {\\n                        'res_model': res_model,\\n                        'partner_id': new_pid,\\n                        'subtype_ids': [(6, 0, partner_data.get(new_pid) or default_subtypes.ids)],\\n                    }))\\n                for new_cid in new_cids:\\n                    command.append((0, 0, {\\n                        'res_model': res_model,\\n                        'channel_id': new_cid,\\n                        'subtype_ids': [(6, 0, channel_data.get(new_cid) or default_subtypes.ids)],\\n                    }))\\n                if command:\\n                    specific[res_id] = command\\n        return generic, specific\\n\\n    #\\n    # Modifying followers change access rights to individual documents. As the\\n    # cache may contain accessible/inaccessible data, one has to refresh it.\\n    #\\n    @api.model\\n    def create(self, vals):\\n        res = super(Followers, self).create(vals)\\n        self.invalidate_cache()\\n        return res\\n\\n    @api.multi\\n    def write(self, vals):\\n        res = super(Followers, self).write(vals)\\n        self.invalidate_cache()\\n        return res\\n\\n    @api.multi\\n    def unlink(self):\\n        res = super(Followers, self).unlink()\\n        self.invalidate_cache()\\n        return res\\n\\n    _sql_constraints = [\\n        ('mail_followers_res_partner_res_model_id_uniq', 'unique(res_model,res_id,partner_id)', 'Error, a partner cannot follow twice the same object.'),\\n        ('mail_followers_res_channel_res_model_id_uniq', 'unique(res_model,res_id,channel_id)', 'Error, a channel cannot follow twice the same object.'),\\n        ('partner_xor_channel', 'CHECK((partner_id IS NULL) != (channel_id IS NULL))', 'Error: A follower must be either a partner or a channel (but not both).')\\n    ]\\n\"}\n",
      "\n",
      "{'repo_name': 'ghandiosm/Test', 'ref': 'refs/heads/master', 'path': 'addons/mail/models/mail_followers.py', 'copies': '26', 'content': '# -*- coding: utf-8 -*-\\n\\nfrom openerp import api, fields, models\\n\\n\\nclass Followers(models.Model):\\n    \"\"\" mail_followers holds the data related to the follow mechanism inside\\n    Odoo. Partners can choose to follow documents (records) of any kind\\n    that inherits from mail.thread. Following documents allow to receive\\n    notifications for new messages. A subscription is characterized by:\\n\\n    :param: res_model: model of the followed objects\\n    :param: res_id: ID of resource (may be 0 for every objects)\\n    \"\"\"\\n    _name = \\'mail.followers\\'\\n    _rec_name = \\'partner_id\\'\\n    _log_access = False\\n    _description = \\'Document Followers\\'\\n\\n    res_model = fields.Char(\\n        \\'Related Document Model\\', required=True, select=1, help=\\'Model of the followed resource\\')\\n    res_id = fields.Integer(\\n        \\'Related Document ID\\', select=1, help=\\'Id of the followed resource\\')\\n    partner_id = fields.Many2one(\\n        \\'res.partner\\', string=\\'Related Partner\\', ondelete=\\'cascade\\', select=1)\\n    channel_id = fields.Many2one(\\n        \\'mail.channel\\', string=\\'Listener\\', ondelete=\\'cascade\\', select=1)\\n    subtype_ids = fields.Many2many(\\n        \\'mail.message.subtype\\', string=\\'Subtype\\',\\n        help=\"Message subtypes followed, meaning subtypes that will be pushed onto the user\\'s Wall.\")\\n\\n    @api.model\\n    def _add_follower_command(self, res_model, res_ids, partner_data, channel_data, force=True):\\n        \"\"\" Please upate me\\n        :param force: if True, delete existing followers before creating new one\\n                      using the subtypes given in the parameters\\n        \"\"\"\\n        force_mode = force or (all(data for data in partner_data.values()) and all(data for data in channel_data.values()))\\n        generic = []\\n        specific = {}\\n        existing = {}  # {res_id: follower_ids}\\n        p_exist = {}  # {partner_id: res_ids}\\n        c_exist = {}  # {channel_id: res_ids}\\n\\n        followers = self.sudo().search([\\n            \\'&\\',\\n            \\'&\\', (\\'res_model\\', \\'=\\', res_model), (\\'res_id\\', \\'in\\', res_ids),\\n            \\'|\\', (\\'partner_id\\', \\'in\\', partner_data.keys()), (\\'channel_id\\', \\'in\\', channel_data.keys())])\\n\\n        if force_mode:\\n            followers.unlink()\\n        else:\\n            for follower in followers:\\n                existing.setdefault(follower.res_id, list()).append(follower)\\n                if follower.partner_id:\\n                    p_exist.setdefault(follower.partner_id.id, list()).append(follower.res_id)\\n                if follower.channel_id:\\n                    c_exist.setdefault(follower.channel_id.id, list()).append(follower.res_id)\\n\\n        default_subtypes = self.env[\\'mail.message.subtype\\'].search([\\n            (\\'default\\', \\'=\\', True),\\n            \\'|\\', (\\'res_model\\', \\'=\\', res_model), (\\'res_model\\', \\'=\\', False)])\\n\\n        if force_mode:\\n            for pid, data in partner_data.iteritems():\\n                if not data:\\n                    partner_data[pid] = default_subtypes.ids\\n            for cid, data in channel_data.iteritems():\\n                if not data:\\n                    channel_data[cid] = default_subtypes.ids\\n\\n        # create new followers, batch ok\\n        gen_new_pids = [pid for pid in partner_data.keys() if pid not in p_exist]\\n        gen_new_cids = [cid for cid in channel_data.keys() if cid not in c_exist]\\n        for pid in gen_new_pids:\\n            generic.append([0, 0, {\\'res_model\\': res_model, \\'partner_id\\': pid, \\'subtype_ids\\': [(6, 0, partner_data.get(pid) or default_subtypes.ids)]}])\\n        for cid in gen_new_cids:\\n            generic.append([0, 0, {\\'res_model\\': res_model, \\'channel_id\\': cid, \\'subtype_ids\\': [(6, 0, channel_data.get(cid) or default_subtypes.ids)]}])\\n\\n        # create new followers, each document at a time because of existing followers to avoid erasing\\n        if not force_mode:\\n            for res_id in res_ids:\\n                command = []\\n                doc_followers = existing.get(res_id, list())\\n\\n                new_pids = set(partner_data.keys()) - set([sub.partner_id.id for sub in doc_followers if sub.partner_id]) - set(gen_new_pids)\\n                new_cids = set(channel_data.keys()) - set([sub.channel_id.id for sub in doc_followers if sub.channel_id]) - set(gen_new_cids)\\n\\n                # subscribe new followers\\n                for new_pid in new_pids:\\n                    command.append((0, 0, {\\n                        \\'res_model\\': res_model,\\n                        \\'partner_id\\': new_pid,\\n                        \\'subtype_ids\\': [(6, 0, partner_data.get(new_pid) or default_subtypes.ids)],\\n                    }))\\n                for new_cid in new_cids:\\n                    command.append((0, 0, {\\n                        \\'res_model\\': res_model,\\n                        \\'channel_id\\': new_cid,\\n                        \\'subtype_ids\\': [(6, 0, channel_data.get(new_cid) or default_subtypes.ids)],\\n                    }))\\n                if command:\\n                    specific[res_id] = command\\n        return generic, specific\\n\\n    #\\n    # Modifying followers change access rights to individual documents. As the\\n    # cache may contain accessible/inaccessible data, one has to refresh it.\\n    #\\n    @api.model\\n    def create(self, vals):\\n        res = super(Followers, self).create(vals)\\n        self.invalidate_cache()\\n        return res\\n\\n    @api.multi\\n    def write(self, vals):\\n        res = super(Followers, self).write(vals)\\n        self.invalidate_cache()\\n        return res\\n\\n    @api.multi\\n    def unlink(self):\\n        res = super(Followers, self).unlink()\\n        self.invalidate_cache()\\n        return res\\n\\n    _sql_constraints = [\\n        (\\'mail_followers_res_partner_res_model_id_uniq\\', \\'unique(res_model,res_id,partner_id)\\', \\'Error, a partner cannot follow twice the same object.\\'),\\n        (\\'mail_followers_res_channel_res_model_id_uniq\\', \\'unique(res_model,res_id,channel_id)\\', \\'Error, a channel cannot follow twice the same object.\\'),\\n        (\\'partner_xor_channel\\', \\'CHECK((partner_id IS NULL) != (channel_id IS NULL))\\', \\'Error: A follower must be either a partner or a channel (but not both).\\')\\n    ]\\n'}\n"
     ]
    }
   ],
   "source": [
    "with open('data/python-000000000000.json', encoding=\"utf8\") as f:\n",
    "    j = f.readline()\n",
    "    j = f.readline()\n",
    "    print(j)\n",
    "    jj = eval(j)\n",
    "    print(jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_name\n",
      "ghandiosm/Test\n",
      "ref\n",
      "refs/heads/master\n",
      "path\n",
      "addons/mail/models/mail_followers.py\n",
      "copies\n",
      "26\n",
      "content\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "from openerp import api, fields, models\n",
      "\n",
      "\n",
      "class Followers(models.Model):\n",
      "    \"\"\" mail_followers holds the data related to the follow mechanism inside\n",
      "    Odoo. Partners can choose to follow documents (records) of any kind\n",
      "    that inherits from mail.thread. Following documents allow to receive\n",
      "    notifications for new messages. A subscription is characterized by:\n",
      "\n",
      "    :param: res_model: model of the followed objects\n",
      "    :param: res_id: ID of resource (may be 0 for every objects)\n",
      "    \"\"\"\n",
      "    _name = 'mail.followers'\n",
      "    _rec_name = 'partner_id'\n",
      "    _log_access = False\n",
      "    _description = 'Document Followers'\n",
      "\n",
      "    res_model = fields.Char(\n",
      "        'Related Document Model', required=True, select=1, help='Model of the followed resource')\n",
      "    res_id = fields.Integer(\n",
      "        'Related Document ID', select=1, help='Id of the followed resource')\n",
      "    partner_id = fields.Many2one(\n",
      "        'res.partner', string='Related Partner', ondelete='cascade', select=1)\n",
      "    channel_id = fields.Many2one(\n",
      "        'mail.channel', string='Listener', ondelete='cascade', select=1)\n",
      "    subtype_ids = fields.Many2many(\n",
      "        'mail.message.subtype', string='Subtype',\n",
      "        help=\"Message subtypes followed, meaning subtypes that will be pushed onto the user's Wall.\")\n",
      "\n",
      "    @api.model\n",
      "    def _add_follower_command(self, res_model, res_ids, partner_data, channel_data, force=True):\n",
      "        \"\"\" Please upate me\n",
      "        :param force: if True, delete existing followers before creating new one\n",
      "                      using the subtypes given in the parameters\n",
      "        \"\"\"\n",
      "        force_mode = force or (all(data for data in partner_data.values()) and all(data for data in channel_data.values()))\n",
      "        generic = []\n",
      "        specific = {}\n",
      "        existing = {}  # {res_id: follower_ids}\n",
      "        p_exist = {}  # {partner_id: res_ids}\n",
      "        c_exist = {}  # {channel_id: res_ids}\n",
      "\n",
      "        followers = self.sudo().search([\n",
      "            '&',\n",
      "            '&', ('res_model', '=', res_model), ('res_id', 'in', res_ids),\n",
      "            '|', ('partner_id', 'in', partner_data.keys()), ('channel_id', 'in', channel_data.keys())])\n",
      "\n",
      "        if force_mode:\n",
      "            followers.unlink()\n",
      "        else:\n",
      "            for follower in followers:\n",
      "                existing.setdefault(follower.res_id, list()).append(follower)\n",
      "                if follower.partner_id:\n",
      "                    p_exist.setdefault(follower.partner_id.id, list()).append(follower.res_id)\n",
      "                if follower.channel_id:\n",
      "                    c_exist.setdefault(follower.channel_id.id, list()).append(follower.res_id)\n",
      "\n",
      "        default_subtypes = self.env['mail.message.subtype'].search([\n",
      "            ('default', '=', True),\n",
      "            '|', ('res_model', '=', res_model), ('res_model', '=', False)])\n",
      "\n",
      "        if force_mode:\n",
      "            for pid, data in partner_data.iteritems():\n",
      "                if not data:\n",
      "                    partner_data[pid] = default_subtypes.ids\n",
      "            for cid, data in channel_data.iteritems():\n",
      "                if not data:\n",
      "                    channel_data[cid] = default_subtypes.ids\n",
      "\n",
      "        # create new followers, batch ok\n",
      "        gen_new_pids = [pid for pid in partner_data.keys() if pid not in p_exist]\n",
      "        gen_new_cids = [cid for cid in channel_data.keys() if cid not in c_exist]\n",
      "        for pid in gen_new_pids:\n",
      "            generic.append([0, 0, {'res_model': res_model, 'partner_id': pid, 'subtype_ids': [(6, 0, partner_data.get(pid) or default_subtypes.ids)]}])\n",
      "        for cid in gen_new_cids:\n",
      "            generic.append([0, 0, {'res_model': res_model, 'channel_id': cid, 'subtype_ids': [(6, 0, channel_data.get(cid) or default_subtypes.ids)]}])\n",
      "\n",
      "        # create new followers, each document at a time because of existing followers to avoid erasing\n",
      "        if not force_mode:\n",
      "            for res_id in res_ids:\n",
      "                command = []\n",
      "                doc_followers = existing.get(res_id, list())\n",
      "\n",
      "                new_pids = set(partner_data.keys()) - set([sub.partner_id.id for sub in doc_followers if sub.partner_id]) - set(gen_new_pids)\n",
      "                new_cids = set(channel_data.keys()) - set([sub.channel_id.id for sub in doc_followers if sub.channel_id]) - set(gen_new_cids)\n",
      "\n",
      "                # subscribe new followers\n",
      "                for new_pid in new_pids:\n",
      "                    command.append((0, 0, {\n",
      "                        'res_model': res_model,\n",
      "                        'partner_id': new_pid,\n",
      "                        'subtype_ids': [(6, 0, partner_data.get(new_pid) or default_subtypes.ids)],\n",
      "                    }))\n",
      "                for new_cid in new_cids:\n",
      "                    command.append((0, 0, {\n",
      "                        'res_model': res_model,\n",
      "                        'channel_id': new_cid,\n",
      "                        'subtype_ids': [(6, 0, channel_data.get(new_cid) or default_subtypes.ids)],\n",
      "                    }))\n",
      "                if command:\n",
      "                    specific[res_id] = command\n",
      "        return generic, specific\n",
      "\n",
      "    #\n",
      "    # Modifying followers change access rights to individual documents. As the\n",
      "    # cache may contain accessible/inaccessible data, one has to refresh it.\n",
      "    #\n",
      "    @api.model\n",
      "    def create(self, vals):\n",
      "        res = super(Followers, self).create(vals)\n",
      "        self.invalidate_cache()\n",
      "        return res\n",
      "\n",
      "    @api.multi\n",
      "    def write(self, vals):\n",
      "        res = super(Followers, self).write(vals)\n",
      "        self.invalidate_cache()\n",
      "        return res\n",
      "\n",
      "    @api.multi\n",
      "    def unlink(self):\n",
      "        res = super(Followers, self).unlink()\n",
      "        self.invalidate_cache()\n",
      "        return res\n",
      "\n",
      "    _sql_constraints = [\n",
      "        ('mail_followers_res_partner_res_model_id_uniq', 'unique(res_model,res_id,partner_id)', 'Error, a partner cannot follow twice the same object.'),\n",
      "        ('mail_followers_res_channel_res_model_id_uniq', 'unique(res_model,res_id,channel_id)', 'Error, a channel cannot follow twice the same object.'),\n",
      "        ('partner_xor_channel', 'CHECK((partner_id IS NULL) != (channel_id IS NULL))', 'Error: A follower must be either a partner or a channel (but not both).')\n",
      "    ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in jj:\n",
    "    print(k)\n",
    "    print(jj[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonASCII(line):\n",
    "    newline = \"\"\n",
    "    for c in line:\n",
    "        if c.isascii():\n",
    "            newline+=c\n",
    "    return newline\n",
    "def replace_url(line):\n",
    "    # there is a longer version: https://gist.github.com/gruber/8891611\n",
    "    regex = re.compile(r\"((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*\", re.IGNORECASE)\n",
    "    newline = re.sub(regex,\"<URL>\",line)\n",
    "    print(newline)\n",
    "    return newline\n",
    "def replace_path(line):\n",
    "    #maybe refer to https://stackoverflow.com/questions/169008/regex-for-parsing-directory-and-filename\n",
    "    regex = re.compile(r\"\\s/?(?:(?P<dir>(?:[/]?)(?:[^\\/^\\s]+/)+)(?P<filename>[^/^.]+\\.[a-z0-9]+))/?\",re.IGNORECASE)\n",
    "    \n",
    "    newline = re.sub(regex,\" <FILE>\",line)\n",
    "    print(newline)\n",
    "    return newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6047\n",
      "6047\n"
     ]
    }
   ],
   "source": [
    "print(len(jj[\"content\"]))\n",
    "print(len(remove_nonASCII(jj[\"content\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you can find the code at <URL> and <URL>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'you can find the code at <URL> and <URL>'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_url(\"you can find the code at https://www.randomurl.com and example.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "refer to <FILE>, and maybe we want to look at usr.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'refer to <FILE>, and maybe we want to look at usr.bin'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_path(\"refer to /var/log/xyz/10032008.log, and maybe we want to look at usr.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal string\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'normal string'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_path(\"normal string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "what <FILE>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'what <FILE>'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_path(\"what var/dslfkj/s/usr.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
