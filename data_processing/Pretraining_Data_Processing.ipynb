{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_files = glob.glob(\"pretrained_data/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretrained_data\\\\python-000000000000.json']\n"
     ]
    }
   ],
   "source": [
    "print(python_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Read All Pretrained Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for file in python_files:\n",
    "    with open(file, encoding=\"utf8\") as f:\n",
    "        entirefile = f.readlines()         \n",
    "        for file in entirefile:\n",
    "            file = eval(file)\n",
    "            data.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Method Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repeated File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove repeated\n",
    "content_dict = defaultdict(list)\n",
    "for idx,d in enumerate(data):\n",
    "    if \"content\" in d:\n",
    "        content = d[\"content\"]\n",
    "        content_dict[content].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original file number: 142982, unique file number: 111687\n"
     ]
    }
   ],
   "source": [
    "print(\"Original file number: {}, unique file number: {}\".format(len(data),len(content_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_content_count = 0\n",
    "filtered_data1 = []\n",
    "for i in content_dict:\n",
    "    if len(content_dict[i]) > 1:\n",
    "        same_content_count += 1\n",
    "    try:\n",
    "        filtered_data1.append(content_dict[i][0])\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_lines = 20\n",
    "filtered_data2 = []\n",
    "for i in filtered_data1:\n",
    "    if data[i][\"content\"].count(\"\\n\") > number_lines:\n",
    "        filtered_data2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique and long file number: 94448\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique and long file number: {}\".format(len(filtered_data2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data3 = []\n",
    "for i in filtered_data2:\n",
    "    if \"LICENSE\" not in data[i][\"path\"]:\n",
    "        filtered_data3.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique and long file and not license number: 94448\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique and long file and not license number: {}\".format(len(filtered_data3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove File that Contains Unpopular Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for idx in filtered_data3:\n",
    "    processed_data.append(data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_data/processed_pretrained_data.json', 'w') as f:\n",
    "    json.dump(processed_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = []\n",
    "with open(\"processed_data/processed_pretrained_data.json\") as f:\n",
    "    data2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\n",
      "\n",
      "# Perform static code analysis\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import shutil\n",
      "import re\n",
      "\n",
      "# Severity levels\n",
      "SEV_OK = 0\n",
      "SEV_INFO = 1\n",
      "SEV_WARNING = 2\n",
      "SEV_ERROR = 3\n",
      "\n",
      "SEV_NAMES = ['OK', 'Note', 'Warning', 'Error'];\n",
      "\n",
      "# Utility functions\n",
      "\n",
      "def init_totals():\n",
      "\treturn [0 for i in range(SEV_ERROR + 1)];\n",
      "\n",
      "def init_errors():\n",
      "\treturn [[] for i in range(SEV_ERROR + 1)];\n",
      "\t\n",
      "def find_scad_file(assembly):\n",
      "    for filename in os.listdir(source_dir):\n",
      "        if filename[-5:] == \".scad\":\n",
      "            #\n",
      "            # look for module which makes the assembly\n",
      "            #\n",
      "            for line in open(source_dir + \"/\" + filename, \"r\").readlines():\n",
      "                words = line.split()\n",
      "                if len(words) and words[0] == \"module\":\n",
      "                    module = words[1].split('(')[0]\n",
      "                    if module == assembly:\n",
      "                        return filename\n",
      "\n",
      "\n",
      "    return None\n",
      "\n",
      "# Faster regex\n",
      "_regexp_compile_cache = {}\n",
      "\n",
      "def recache(pattern):\n",
      "    if pattern not in _regexp_compile_cache:\n",
      "        _regexp_compile_cache[pattern] = re.compile(pattern)\n",
      "        # print('Caching: '+pattern)\n",
      "    return _regexp_compile_cache[pattern]\n",
      "\n",
      "def match(pattern, s):\n",
      "  \"\"\"Matches the string with the pattern, caching the compiled regexp.\"\"\"\n",
      "  p = recache(pattern)\n",
      "  return p.match(s) != None\n",
      "\t\n",
      "\n",
      "# Reusable regex patterns\n",
      "re_modules = (r\"\\bmodule\\s+(\", r\")\\s*\\(\\s*\");\n",
      "re_functions = (r\"\\bfunction\\s+(\", r\")\\s*\\(\");\n",
      "re_includes = (r\"[^//]\\binclude\\s+[\\<\\\"](\", r\")[\\>\\\"]\");\n",
      "re_uses = (r\"\\buse\\s+[\\<\\\"](\", r\")[\\>\\\"]\");\n",
      "\n",
      "re_upper_camel_case = \"([A-Z][a-z0-9]+)+\";\n",
      "re_upper_camel_case_with_abbr = \"([A-Z]+[a-z0-9]*)+\";\n",
      "\n",
      "re_supplementary_modules = \"(_*[A-Z]+[a-z0-9]*)*\";\n",
      "\n",
      "\n",
      "def extract_definitions(fpath, name_re=r\"\\w+\", def_re=\"\"):\n",
      "    pattern = name_re.join(def_re)\n",
      "    matcher = recache(pattern)\n",
      "    fpath.seek(0)\n",
      "    return [m.group(1) for m in matcher.finditer(fpath.read())]\n",
      "\n",
      "def extract_mod_names(fpath, name_re=r\"\\w+\"):\n",
      "    return extract_definitions(fpath, name_re=name_re, def_re=re_modules)\n",
      "\n",
      "def extract_func_names(fpath, name_re=r\"\\w+\"):\n",
      "    return extract_definitions(fpath, name_re=name_re, def_re=re_functions)\n",
      "    \n",
      "def extract_includes(fpath, name_re=r\"[\\w\\.\\\\\\/]+\"):\n",
      "    return extract_definitions(fpath, name_re=name_re, def_re=re_includes)\n",
      "\t\n",
      "def extract_uses(fpath, name_re=r\"[\\w\\.\\\\\\/]+\"):\n",
      "    return extract_definitions(fpath, name_re=name_re, def_re=re_uses)\n",
      "\t\n",
      "\"\"\"\n",
      "Report structure\n",
      "\n",
      "report ->\n",
      "\tcount by severity\n",
      "\tsection ->\n",
      "\t\tcount by severity\n",
      "\t\tfile ->\n",
      "\t\t\tcount by severity\n",
      "\t\t\terrors [ severity ] [ item ] =  description\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "# Global vars\n",
      "\t\n",
      "report = {'totals':init_totals(), 'sections': {} }\n",
      "\n",
      "# rules\n",
      "\n",
      "def rr(isok, sevbad, desc):\n",
      "    return { \n",
      "\t    'sev': SEV_OK if isok else sevbad, \n",
      "\t    'desc':desc\n",
      "\t    }\n",
      "\t\n",
      "def filename_format_ucc(fn):\n",
      "\treturn rr(match(re_upper_camel_case_with_abbr, fn[:-5]), SEV_WARNING, 'Filename is not in UpperCamelCase')\n",
      "\t\n",
      "def assembly_module_name_matches_filename(f):\n",
      "    return rr(f['name'][:-5]+'Assembly' in f['modules'], SEV_ERROR, 'Assembly module name does not match filename')\n",
      "    \n",
      "def vitamin_module_name_matches_filename(f):\n",
      "    return rr(f['name'][:-5] in f['modules'], SEV_WARNING, 'Vitamin module name does not match filename')\n",
      "\n",
      "def no_includes(f):\n",
      "    return rr(len(f['includes'])==0, SEV_WARNING, 'Contains include statements - these should be in the relevant global config file')\n",
      "\n",
      "def no_uses(f):\n",
      "    return rr(len(f['uses'])==0, SEV_WARNING, 'Contains use statements')\n",
      "\n",
      "def supplementary_module_naming(f):\n",
      "    errors = 0\n",
      "    s = ''\n",
      "    prefix = f['name'][:-5]\n",
      "    for m in f['modules']:\n",
      "        if not match(prefix + re_supplementary_modules, m):\n",
      "            if s > '':\n",
      "                s += ', '\n",
      "            s += m\n",
      "            errors += 1\n",
      "    \n",
      "    return rr(errors == 0, SEV_WARNING, str(errors)+' supplementary modules do not comply with naming convention ('+s+')')\n",
      "    \n",
      "def function_naming(f):\n",
      "    errors = 0\n",
      "    s = ''\n",
      "    prefix = f['name'][:-5]\n",
      "    for m in f['functions']:\n",
      "        if not match(prefix + re_supplementary_modules, m):\n",
      "            if s > '':\n",
      "                s += ', '\n",
      "            s += m\n",
      "            errors += 1\n",
      "    \n",
      "    return rr(errors == 0, SEV_WARNING, str(errors)+' functions do not comply with naming convention ('+s+')')\n",
      "\n",
      "\n",
      "# * Assembly module contains step() calls\n",
      "# * Any variables have correct naming convention\n",
      "# * Any functions have correct naming convention\n",
      "# * Any included _STL modules have associated _View modules\n",
      "# * _View modules contain an echo line with correct structure\n",
      "# * Exists in /config/assemblies.scad\n",
      "\n",
      "\n",
      "\t\n",
      "# section processors\n",
      "\n",
      "def add_result(f, res):\n",
      "    f['totals'][res['sev']] += 1\n",
      "    f['errors'][res['sev']].append(res['desc'])\n",
      "    \n",
      "def extract_all(f, file):\n",
      "    f['modules'] = extract_mod_names(file)\n",
      "    f['functions'] = extract_func_names(file)\n",
      "    f['includes'] = extract_includes(file)\n",
      "    f['uses'] = extract_uses(file)\n",
      "    \n",
      "def proc_assemblies(f):\n",
      "    fn = f['name']\n",
      "    print(\"  Validating: \"+fn)\n",
      "    \n",
      "    fpath = f['dir']+'/'+f['name']\n",
      "    file = open(fpath, 'r')\n",
      "    \n",
      "    extract_all(f, file)\n",
      "    \n",
      "    # Apply validation rules\n",
      "    add_result(f, filename_format_ucc(fn))\n",
      "    add_result(f, assembly_module_name_matches_filename(f))\n",
      "    add_result(f, no_includes(f))\n",
      "    add_result(f, no_uses(f))\n",
      "    add_result(f, supplementary_module_naming(f))\n",
      "    add_result(f, function_naming(f))\n",
      "    \n",
      "def proc_vitamins(f):\n",
      "    fn = f['name']\n",
      "    print(\"  Validating: \"+fn)\n",
      "    \n",
      "    fpath = f['dir']+'/'+f['name']\n",
      "    file = open(fpath, 'r')\n",
      "    \n",
      "    extract_all(f, file)\n",
      "    \n",
      "    # Apply validation rules\n",
      "    add_result(f, filename_format_ucc(fn))\n",
      "    add_result(f, vitamin_module_name_matches_filename(f))\n",
      "    add_result(f, supplementary_module_naming(f))\n",
      "    add_result(f, function_naming(f))\n",
      "\t\n",
      "\t\n",
      "# stuff\t\n",
      "\n",
      "def update_section_totals(sec):\n",
      "\tfor f in sec['files']:\n",
      "\t    for i in range(SEV_ERROR+1):\n",
      "\t        sec['totals'][i] += sec['files'][f]['totals'][i]\n",
      "\t\n",
      "def add_file(sec, dir, fn):\n",
      "\tf = {'name':fn, 'dir':dir, 'totals':init_totals(), 'errors':init_errors() }\n",
      "\tsec['files'][fn] = f\n",
      "\treturn f\n",
      "\t\n",
      "def do_section(target_dir, processor, sec):\n",
      "\tprint(\"Section: \"+target_dir)\n",
      "\tfor filename in os.listdir(target_dir):\n",
      "\t\tif filename[-5:] == \".scad\":\n",
      "\t\t\tprocessor(add_file(sec, target_dir, filename))\n",
      "\n",
      "\tupdate_section_totals(sec)\n",
      "\t\n",
      "def add_section(s):\n",
      "\tsec = {'name':s, 'totals':init_totals(), 'files':{} }\n",
      "\treport['sections'][s] = sec\n",
      "\treturn sec\n",
      "\t\n",
      "def update_totals():\n",
      "    for sec in report['sections']:\n",
      "        for i in range(SEV_ERROR+1):\n",
      "            report['totals'][i] += report['sections'][sec]['totals'][i]\n",
      "\n",
      "\n",
      "# Saving\n",
      "\n",
      "def to_anchor_link(s):\n",
      "    return '['+s+'](#'+s.lower().replace('.','')+')'\n",
      "\n",
      "def writeln(f, s):\n",
      "    f.write(s + '\\n');\n",
      "    \n",
      "def fit_to_publish():\n",
      "    return True if report['totals'][SEV_ERROR] == 0 else False\n",
      "\n",
      "def write_summary(f):\n",
      "    writeln(f,'## Summary')\n",
      "    writeln(f,'')\n",
      "    \n",
      "    writeln(f,'**Fit to Publish:** '+ ('Yes' if fit_to_publish() else 'No' ))\n",
      "    writeln(f,'')\n",
      "    \n",
      "    # workout longest section name\n",
      "    secchars = 8;\n",
      "    for sec in report['sections']:\n",
      "        if len(sec) > secchars:\n",
      "            secchars = len(sec)\n",
      "        \n",
      "    headings = 'Section '.ljust(secchars)\n",
      "    underline = '------'.ljust(secchars,'-') + ' '\n",
      "    for i in range(SEV_ERROR+1):\n",
      "        headings += ' | '+ SEV_NAMES[i].ljust(3)\n",
      "        underline += '|:'.ljust(len(SEV_NAMES[i])-1,'-') + '---:'\n",
      "    writeln(f,headings)\n",
      "    writeln(f,underline)\n",
      "    print(headings)\n",
      "    print(underline)\n",
      "    \n",
      "    for sec in report['sections']:\n",
      "        secn = sec.ljust(secchars)\n",
      "        secl = to_anchor_link(secn)\n",
      "        for i in range(SEV_ERROR+1):\n",
      "            s = ' | '+str(report['sections'][sec]['totals'][i]).ljust(3 if len(SEV_NAMES[i])<3 else len(SEV_NAMES[i]))\n",
      "            secn += s\n",
      "            secl += s\n",
      "        writeln(f,secl)\n",
      "        print(secn)\n",
      "        \n",
      "    f.write('**Total** ')\n",
      "    for i in range(SEV_ERROR+1):\n",
      "        f.write(' | **'+str(report['totals'][i]) + '** ')\n",
      "    writeln(f,'')\n",
      "        \n",
      "    writeln(f,'')\n",
      "    \n",
      "def write_section_summary(f, sec):\n",
      "    writeln(f,'## ' + sec)\n",
      "    writeln(f,'')\n",
      "        \n",
      "    headings = 'File    '\n",
      "    underline = '------ '\n",
      "    for i in range(SEV_ERROR+1):\n",
      "        headings += ' | '+ SEV_NAMES[i]\n",
      "        underline += ' | :---: '\n",
      "    writeln(f,headings)\n",
      "    writeln(f,underline)\n",
      "    \n",
      "    for file in report['sections'][sec]['files']:\n",
      "        f.write(to_anchor_link(file))\n",
      "        for i in range(SEV_ERROR+1):\n",
      "            f.write(' | '+str(report['sections'][sec]['files'][file]['totals'][i]))\n",
      "        writeln(f,'')\n",
      "        \n",
      "    f.write('**Total** ')\n",
      "    for i in range(SEV_ERROR+1):\n",
      "        f.write(' | **'+str(report['sections'][sec]['totals'][i]) + '** ')\n",
      "    writeln(f,'')\n",
      "        \n",
      "    writeln(f,'')\n",
      "    \n",
      "\n",
      "def write_file_summary(f, sec, file):\n",
      "    seco = report['sections'][sec]\n",
      "    fileo = seco['files'][file]\n",
      "        \n",
      "    bad_things = 0\n",
      "    for i in range(1,SEV_ERROR + 1):\n",
      "        bad_things += fileo['totals'][i]\n",
      "        \n",
      "    if (bad_things > 0):\n",
      "        writeln(f,'### ' + file)\n",
      "        writeln(f,'')\n",
      "    \n",
      "        for i in range(1,SEV_ERROR + 1):\n",
      "            if fileo['totals'][i] > 0:\n",
      "                writeln(f, '* **'+SEV_NAMES[i]+'s**')\n",
      "                for d in fileo['errors'][i]:\n",
      "                    writeln(f, '  * '+d)\n",
      "                writeln(f,'')\n",
      "    \n",
      "\n",
      "def save_report():\n",
      "    print(\"Saving report...\")\n",
      "    print(\"\")\n",
      "    f = open('static.md', \"w\")\n",
      "    \n",
      "    writeln(f,'# Static Analysis Report')\n",
      "    writeln(f,'')\n",
      "    \n",
      "    write_summary(f);\n",
      "    \n",
      "    for sec in report['sections']:\n",
      "        write_section_summary(f, sec)\n",
      "        \n",
      "        for file in report['sections'][sec]['files']:\n",
      "            write_file_summary(f, sec, file)\n",
      "    \n",
      "    f.close()\n",
      "\t\n",
      "def static():\n",
      "\tprint()\n",
      "\tprint(\"Static Analysis\")\n",
      "\tprint(\"---------------\")\n",
      "\t\n",
      "\tdo_section('assemblies', proc_assemblies, add_section('Assemblies'))\n",
      "\tdo_section('vitamins', proc_vitamins, add_section('Vitamins'))\n",
      "\t\n",
      "\tupdate_totals()\n",
      "\t\n",
      "\tsave_report()\n",
      "\t\n",
      "\tprint()\n",
      "\t\n",
      "\treturn (0 if fit_to_publish() else 1)\n",
      "\t\n",
      "if __name__ == '__main__':\n",
      "    sys.exit(static())\n"
     ]
    }
   ],
   "source": [
    "print(data2[0][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
